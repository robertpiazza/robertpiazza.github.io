{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c1b2c7b",
   "metadata": {},
   "source": [
    "# Ranking My Friends on Generals\n",
    "\n",
    "- During the course of the pandemic, I started playing a decade old game called Command&Conquer Generals:Zero Hour with my brother and a bunch of friends. \n",
    "\n",
    "- Out of curiousity, we started keeping track of the stats from all the games and show wins and losses for each person. \n",
    "\n",
    "- This is a team game though so being able to pull out an individual's overall excellence and measure of how much better the person was a little more tricky. \n",
    "\n",
    "- For this project, I wanted to ingest the stats, create a model for predicting each person's relative strength, and end up with a score that could be used to create more even teams for future games. \n",
    "\n",
    "The scores are stored in a google sheet located [here](https://docs.google.com/spreadsheets/d/1ks6mqMbTgVFkQE-rZDByKVnGH4WMRMOdLSdabeMfZaA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#---\n",
    "#Created on Mon Feb  8 09:36:57 2021\n",
    "\n",
    "#---\n",
    "###\n",
    "\n",
    "#import all the libraries we'll use\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean, std\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "RANDOM_STATE = 42 \n",
    "MAX_NUMBER_OF_GAMES = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016ab9a5",
   "metadata": {},
   "source": [
    "The games were stored on a google sheet so the following functions ingest the most up-to-date data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsheet_api_check(SCOPES):\n",
    "    creds = None\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "    return creds\n",
    "\n",
    "def pull_sheet_data(SCOPES,SPREADSHEET_ID,DATA_TO_PULL):\n",
    "    creds = gsheet_api_check(SCOPES)\n",
    "    service = build('sheets', 'v4', credentials=creds)\n",
    "    sheet = service.spreadsheets()\n",
    "    result = sheet.values().get(\n",
    "        spreadsheetId=SPREADSHEET_ID,\n",
    "        range=DATA_TO_PULL).execute()\n",
    "    values = result.get('values', [])\n",
    "    \n",
    "    if not values:\n",
    "        print('No data found.')\n",
    "    else:\n",
    "        rows = sheet.values().get(spreadsheetId=SPREADSHEET_ID,\n",
    "                                  range=DATA_TO_PULL).execute()\n",
    "        data = rows.get('values')\n",
    "        print(\"COMPLETE: Data copied\")\n",
    "        return data\n",
    "    \n",
    "def push_sheet_data(SCOPES,SPREADSHEET_ID,RANGE, DATA_TO_PUSH):\n",
    "    creds = gsheet_api_check(SCOPES)\n",
    "    service = build('sheets', 'v4', credentials=creds)\n",
    "    sheet = service.spreadsheets()\n",
    "    body = {\n",
    "        'values': DATA_TO_PUSH\n",
    "    }\n",
    "    result = sheet.values().update(\n",
    "        spreadsheetId=SPREADSHEET_ID, range=RANGE,\n",
    "        valueInputOption='USER_ENTERED', body=body).execute()\n",
    "    data = result.get('updatedCells')\n",
    "    print('{0} cells updated.'.format(data))\n",
    "    \n",
    "    return data    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28feb2b",
   "metadata": {},
   "source": [
    "## Import Data from Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# If modifying these scopes, delete the file token.pickle.\n",
    "#SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "\n",
    "# The ID and range of a sample spreadsheet.\n",
    "SPREADSHEET_ID = '1ks6mqMbTgVFkQE-rZDByKVnGH4WMRMOdLSdabeMfZaA'\n",
    "\n",
    "#Pulls data from the entire spreadsheet tab.\n",
    "#DATA_TO_PULL = 'Games'\n",
    "#or\n",
    "#Pulls data only from the specified range of cells.\n",
    "DATA_TO_PULL = 'Games!A1:Q4000'\n",
    "data = pull_sheet_data(SCOPES,SPREADSHEET_ID,DATA_TO_PULL)\n",
    "games = pd.DataFrame(data[1:], columns=data[0])\n",
    "games = games.set_index('Index',drop=True)\n",
    "#df.head()\n",
    "\n",
    "numeric_columns = ['Team', 'Win', 'Game', 'Units Created',\n",
    "       'Units Lost', 'Units Destroyed', 'Buildings Constructed',\n",
    "       'Buildings Lost', 'Buildings Destroyed', 'Supplies Collected', 'Rank',\n",
    "       'Inverse Rank', 'Normalized Rank']\n",
    "\n",
    "for col in numeric_columns:\n",
    "    games[col] = pd.to_numeric(games[col]).copy()\n",
    "games['Date'] = pd.to_datetime(games['Date'])\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98770d3a",
   "metadata": {},
   "source": [
    "## Basic Cleaning\n",
    "\n",
    "There may be some rows of data that need cleaning. \n",
    "The main method of dealing with it is to eliminate the problem games since we have enough data regardless. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d4d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Remove any row that doesn't have an index\n",
    "games = games[(~games.index.isna())&(~games.Game.isna())].copy()\n",
    "\n",
    "#Set the Game row to be integers instead of floats since we'll use it to make ranges\n",
    "games.loc[:,'Game']=games.Game.astype(np.int32)\n",
    "\n",
    "#Remove any game where team data isn't present and only include the columns up to Normalized Rank\n",
    "games=games.loc[~games.Team.isna(),games.columns[0:16]].copy()\n",
    "\n",
    "#Win's are designated with a 1 if there's a win, and are empty (NA) if it's a loss\n",
    "#If it's a loss, we need to use a 0, otherwise it will throw off our average win calculations\n",
    "games.loc[games.Win.isna(),'Win'] = games.loc[games.Win.isna(),'Win'].fillna(0)\n",
    "\n",
    "#For every person calculate Win ratio and average rank from normalized rankings\n",
    "for name in games.Name.unique():\n",
    "    #print(name)\n",
    "    games.loc[games.Name==name,'Win Ratio'] = games.loc[games.Name==name,'Win'].mean()\n",
    "    games.loc[games.Name==name,'Avg Rank'] = games.loc[games.Name==name,'Normalized Rank'].mean()\n",
    "\n",
    "#We use team 1 to designate which team won in another program to see which people win and lose the most together,\n",
    "#but we need to mix this up or the computer's predictive model would take that as way to easily cheat.\n",
    "\n",
    "for i in range( int(games.Game.max()+1)):\n",
    "    #randomize the team numbers for each game\n",
    "    team_1 = np.random.choice([0,1])\n",
    "    team_2 = 1-team_1\n",
    "    games.loc[(games.Game==i)&(games.Team==1),'Team'] = team_1\n",
    "    games.loc[(games.Game==i)&(games.Team==2),'Team'] = team_2\n",
    "    \n",
    "games.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72b878",
   "metadata": {},
   "source": [
    "## Create New Training Data\n",
    "\n",
    "We're now going to create synthetic training data. \n",
    "For this, we'll look at each player's statistics, figure out for this particular game, what his stats were for the last N games, take the average, and use that as their nominal stats each game, then pretend the two teams played each other and make the logistic regression model predict which team will win. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d2185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column that contains the winning team\n",
    "df =  pd.DataFrame(games.loc[games.Win==1,:].groupby('Game').mean().Team.astype(np.int32))\n",
    "df.columns = ['Winning_Team']\n",
    "\n",
    "#We'll use this for segmenting out which columns to use for predicting the winning team\n",
    "prediction_columns = ['Units Created', \n",
    "                      'Units Lost', \n",
    "                      'Units Destroyed',\n",
    "                      'Buildings Constructed',\n",
    "                      'Buildings Lost', \n",
    "                      'Buildings Destroyed', \n",
    "                      'Supplies Collected', \n",
    "                      'Avg Rank', \n",
    "                      'Win Ratio']\n",
    "\n",
    "games_copy = games.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61face",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each player, and each game, create their average win and rank stats for the previous N games\n",
    "for i in range( int(games_copy.Game.max()+1)):\n",
    "    for name in games_copy.loc[games_copy.Game==i,'Name'].unique():\n",
    "        name_bool=games_copy.Name==name\n",
    "        game_bool=games_copy.Game==i\n",
    "        games_copy.loc[(name_bool)&(game_bool),'Win Ratio'] = games_copy.loc[(name_bool)&(games_copy.Game<=i),'Win'].tail(MAX_NUMBER_OF_GAMES).mean()\n",
    "        games_copy.loc[(name_bool)&(game_bool),'Avg Rank'] = games_copy.loc[(name_bool)&(games_copy.Game<=i),'Normalized Rank'].tail(MAX_NUMBER_OF_GAMES).mean()\n",
    "games_copy.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21dc65",
   "metadata": {},
   "source": [
    "## Reduce each game to a single row of stats\n",
    "- For predicting each game, we're going to sum the stats for each team, then take the difference. \n",
    "- For games with large negative numbers, this will indicate that team 0 won, for mostly positive, it would show team 1 won.\n",
    "- For predicting each game, most of the stats should be added except for the game, team, and win stats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c37e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = games_copy.loc[games_copy.Team==1,:].iloc[:,3:].groupby('Game').agg({'Team':'mean', \n",
    "                                                           'Win':'mean', \n",
    "                                                           'Game':'mean', \n",
    "                                                           'Units Created':'sum', \n",
    "                                                           'Units Lost':'sum', \n",
    "                                                           'Units Destroyed':'sum',\n",
    "                                                           'Buildings Constructed':'sum', \n",
    "                                                           'Buildings Lost':'sum', \n",
    "                                                           'Buildings Destroyed':'sum',\n",
    "                                                           'Supplies Collected':'sum', \n",
    "                                                           'Rank':'sum', \n",
    "                                                           'Inverse Rank':'sum', #not used\n",
    "                                                           'Normalized Rank':'sum', #not used\n",
    "                                                           'Win Ratio':'sum', \n",
    "                                                           'Avg Rank':'sum' \n",
    "                                                           }) - games_copy.loc[\n",
    "                                                               games_copy.Team==0,:].iloc[:,3:].groupby('Game').agg({'Team':'mean', \n",
    "                                                           'Win':'mean', \n",
    "                                                           'Game':'mean', \n",
    "                                                           'Units Created':'sum', \n",
    "                                                           'Units Lost':'sum', \n",
    "                                                           'Units Destroyed':'sum',\n",
    "                                                           'Buildings Constructed':'sum', \n",
    "                                                           'Buildings Lost':'sum', \n",
    "                                                           'Buildings Destroyed':'sum',\n",
    "                                                           'Supplies Collected':'sum', \n",
    "                                                           'Rank':'sum', \n",
    "                                                           'Inverse Rank':'sum', #not used\n",
    "                                                           'Normalized Rank':'sum', #not used\n",
    "                                                           'Win Ratio':'sum', \n",
    "                                                           'Avg Rank':'sum', \n",
    "                                                           })\n",
    "\n",
    "#create the difference columns\n",
    "diff_cols = []\n",
    "for col in prediction_columns:\n",
    "    column_name = col+'_diff'\n",
    "    diff_cols += [column_name]\n",
    "    #this really isn't needed anymore but the winning team will still be needed for training value\n",
    "    df.loc[:,column_name] = values.loc[:,col]\n",
    "    \n",
    "#create nominal game stats based on median stats for each player    \n",
    "predicted_games = []    \n",
    "\n",
    "#make stats for each game\n",
    "for game in games_copy.Game.unique():  \n",
    "    #print('game ', game)\n",
    "    team_values = []\n",
    "    \n",
    "    #make stats for each team\n",
    "    for team in range(2):\n",
    "        #print('team ', team)\n",
    "        names = []\n",
    "        #make stats for each player on this team\n",
    "        games_copy.loc[(games_copy.Name==name)&(games.Game<=i),'Win'].tail(MAX_NUMBER_OF_GAMES).mean()\n",
    "        for name in games_copy.loc[(games_copy.Game==game)&(games_copy.Team==team),'Name'].values:\n",
    "            name_stats = games_copy.loc[(games_copy.Name==name)&(games.Game<=game)].tail(MAX_NUMBER_OF_GAMES).iloc[:,6:].median()\n",
    "            name_stats['Win Ratio'] = games_copy.loc[(games_copy.Name==name)&(games_copy.Game<=game),'Win'].tail(MAX_NUMBER_OF_GAMES).mean()\n",
    "            name_stats['Avg Rank'] = games_copy.loc[(games_copy.Name==name)&(games_copy.Game<=game),'Normalized Rank'].tail(MAX_NUMBER_OF_GAMES).mean()\n",
    "            names += [name_stats]\n",
    "            names[-1].loc['Win_avg'] = games_copy.loc[(games_copy.Name==name)&\n",
    "                                                      (~games_copy.Team.isna())&\n",
    "                                                      (games_copy.Game<=game)].Win.fillna(0).tail(MAX_NUMBER_OF_GAMES).mean()\n",
    "            #print(name)\n",
    "        #combine all the medians and sum them together\n",
    "        #Summing works better than an average or median since if the teams have uneven number of players, the weight is on the side with more players\n",
    "\n",
    "        team_values  += [pd.concat(names, axis = 1).T.sum()]\n",
    "    predicted_games +=[team_values[1]-team_values[0]]\n",
    "X_generated = pd.concat(predicted_games, axis = 1).T[prediction_columns]\n",
    "X_generated.columns = diff_cols\n",
    "X_generated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24994016",
   "metadata": {},
   "source": [
    "## Prediction Test\n",
    "\n",
    "Create a logistic regression model, with test and training splits, and 10 cross validation folds for determing accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02877edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict     \n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "y_cols= ['Winning_Team']\n",
    "X = X_generated\n",
    "y = np.ravel(df[y_cols])\n",
    "\n",
    "#standard test, train split should be 20-30% held back for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "#cross validation\n",
    "cv = KFold(n_splits = 10, random_state=10, shuffle=True)\n",
    "\n",
    "\n",
    "#solvers = ['newton-cg', 'lbfgs','liblinear', 'sag', 'saga']\n",
    "#Cs = [1, 3, 10, 30, 100]\n",
    "#parameters = {'logisticregression__solver':solvers, 'logisticregression__C':Cs}\n",
    "\n",
    "#create model\n",
    "#model = LogisticRegression(solver='lbfgs')\n",
    "scaler = StandardScaler()\n",
    "logreg = LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "#X_train = df[X_cols]\n",
    "#y_train = np.ravel(df[y_cols])\n",
    "#y_test = np.ravel(df[y_cols])\n",
    "\n",
    "#simple pipeline of normalizing all the stats then applying logistic regression\n",
    "pipe = make_pipeline(scaler, logreg)\n",
    "\n",
    "#clf = GridSearchCV(pipe, parameters, cv=10)\n",
    "\n",
    "#clf.fit(X, y)\n",
    "pipe.fit(X_train, y_train)  # apply scaling on training data\n",
    "pipe.fit(X, y)\n",
    "#sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e424194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#score it\n",
    "scores = cross_val_score(pipe, X, y, scoring = 'accuracy', cv=cv, n_jobs = -1)\n",
    "print('10-fold cross validation accuracy: %.3f (%.3f stdev)' % (mean(scores), std(scores)))\n",
    "\n",
    "#score it\n",
    "print(\"Accuracy Score is \" + \"{:.2%}\".format(pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65388b16",
   "metadata": {},
   "source": [
    "## Gridsearch\n",
    "I used the below code block for testing a grid search but after finding my best values, I stuck with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%Grid of gridsearch\n",
    "# def make_heatmap(ax, gs, is_sh=False, make_cbar=False):\n",
    "#     \"\"\"Helper to make a heatmap.\"\"\"\n",
    "#     results = pd.DataFrame.from_dict(gs.cv_results_)\n",
    "#     results['params_str'] = results.params.apply(str)\n",
    "#     if is_sh:\n",
    "#         # SH dataframe: get mean_test_score values for the highest iter\n",
    "#         scores_matrix = results.sort_values('iter').pivot_table(\n",
    "#                 index='param_logisticregression__solver', columns='param_logisticregression__C',\n",
    "#                 values='mean_test_score', aggfunc='last'\n",
    "#         )\n",
    "#     else:\n",
    "#         scores_matrix = results.pivot(index='param_logisticregression__solver', columns='param_logisticregression__C',\n",
    "#                                       values='mean_test_score')\n",
    "\n",
    "#     im = ax.imshow(scores_matrix)\n",
    "\n",
    "#     ax.set_xticks(np.arange(len(Cs)))\n",
    "#     ax.set_xticklabels([x for x in Cs])\n",
    "#     ax.set_xlabel('C', fontsize=15)\n",
    "\n",
    "#     ax.set_yticks(np.arange(len(solvers)))\n",
    "#     ax.set_yticklabels([x for x in solvers])\n",
    "#     ax.set_ylabel('solver', fontsize=15)\n",
    "\n",
    "#     # Rotate the tick labels and set their alignment.\n",
    "#     plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "#              rotation_mode=\"anchor\")\n",
    "\n",
    "#     if is_sh:\n",
    "#         iterations = results.pivot_table(index='param_gamma',\n",
    "#                                          columns='param_C', values='iter',\n",
    "#                                          aggfunc='max').values\n",
    "#         for i in range(len(solvers)):\n",
    "#             for j in range(len(Cs)):\n",
    "#                 ax.text(j, i, iterations[i, j],\n",
    "#                         ha=\"center\", va=\"center\", color=\"w\", fontsize=20)\n",
    "\n",
    "#     if make_cbar:\n",
    "#         fig.subplots_adjust(right=0.8)\n",
    "#         cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "#         fig.colorbar(im, cax=cbar_ax)\n",
    "#         cbar_ax.set_ylabel('mean_test_score', rotation=-90, va=\"bottom\",\n",
    "#                            fontsize=15)\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=1, sharey=True)\n",
    "# ax2 = axes\n",
    "\n",
    "# make_heatmap(ax2, clf, make_cbar=True)\n",
    "\n",
    "\n",
    "# ax2.set_title('GridSearch', fontsize=15)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4541b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%    importance of each feature, magnitude matters more than sign\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x = np.arange(len(pipe.steps[1][1].coef_[0])), height = pipe.steps[1][1].coef_[0])\n",
    "ax.set_xticks(np.arange(len(prediction_columns)))\n",
    "ax.set_xticklabels(prediction_columns)\n",
    "plt.xticks(rotation=-90)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eba66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "#chances of one team possibilities\n",
    "\n",
    "first_team=['Shift'] \n",
    "second_team= ['Hard', 'Hard',]\n",
    "test_team = [first_team, second_team]\n",
    "predicted_games = []\n",
    "team_values = []\n",
    "for team in range(2):\n",
    "    #print('team ', team)\n",
    "    names = []\n",
    "    for name in test_team[team]:\n",
    "        if name not in games.Name.unique():\n",
    "            print(name +' not found')\n",
    "            break\n",
    "        name_stats = games_copy.loc[(games_copy.Name==name)].tail(MAX_NUMBER_OF_GAMES).iloc[:,6:].median()\n",
    "        name_stats['Win Ratio'] = games_copy.loc[(games_copy.Name==name)&(games_copy.Game<=game),'Win'].tail(MAX_NUMBER_OF_GAMES).mean()\n",
    "        name_stats['Avg Rank'] = games_copy.loc[(games_copy.Name==name)&(games_copy.Game<=game),'Normalized Rank'].tail(MAX_NUMBER_OF_GAMES).mean()\n",
    "        names += [name_stats]\n",
    "        names[-1].loc['Win_avg'] = games_copy.loc[(games_copy.Name==name)&\n",
    "                                                  (~games_copy.Team.isna())&\n",
    "                                                  (games_copy.Game<=game)].Win.fillna(0).tail(MAX_NUMBER_OF_GAMES).mean()\n",
    "\n",
    "    team_values  += [pd.concat(names, axis = 1).T.sum()]\n",
    "predicted_games +=[team_values[1]-team_values[0]]\n",
    "X_predict = pd.concat(predicted_games, axis = 1).T[prediction_columns]\n",
    "predicted_win = pipe.predict(X_predict)[0]\n",
    "probability = pipe.predict_proba(X_predict)[0][predicted_win]\n",
    "    #possibilities +=[{\"Team 1\":first_team, \"Team 2\":second_team, \"Predicted Team\": predicted_win+1, \"Probability\": probability}]\n",
    "\n",
    "#print('\\n\\nBetween '+ ', '.join(first_team)+' and ' + ', '.join(second_team)+ ',\\nI predict ' + ', '.join(test_team[predicted_win]) + ' with a '+\"{:.2%}\".format(probability)+' chance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a3b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "#all possibilities\n",
    "all_names = ['Neo', 'Shift','Matt', 'Spiff', 'Skippy', 'STM', 'Jack', 'Mike']\n",
    "possibilities = []\n",
    "\n",
    "non_parity_combos= int(len(list(combinations(all_names,int(len(all_names)/2))))/2)\n",
    "for combo in list(combinations(all_names,int(len(all_names)/2)))[0:non_parity_combos]:\n",
    "    first_team=list(combo)\n",
    "    second_team= [x for x in all_names if x not in combo]\n",
    "    test_team = [first_team, second_team]\n",
    "    predicted_games = []\n",
    "    team_values = []\n",
    "    for team in range(2):\n",
    "        #print('team ', team)\n",
    "        names = []\n",
    "        for name in test_team[team]:\n",
    "            names += [games.loc[games.Name==name].iloc[:,6:].mean()]\n",
    "            names[-1].loc['Win_avg'] = games.loc[(games.Name==name)&(~games.Team.isna())].Win.fillna(0).mean()\n",
    "        team_values  += [pd.concat(names, axis = 1).T.mean()]\n",
    "    predicted_games +=[team_values[1]-team_values[0]]\n",
    "    X_predict = pd.concat(predicted_games, axis = 1).T[prediction_columns]\n",
    "    predicted_win = pipe.predict(X_predict)[0]\n",
    "    probability = pipe.predict_proba(X_predict)[0][predicted_win]\n",
    "    possibilities +=[{\"Team 1\":first_team, \"Team 2\":second_team, \"Predicted Team\": predicted_win+1, \"Probability\": probability}]\n",
    "all_runs = pd.DataFrame(possibilities)\n",
    "#print('\\n\\nBetween '+ ', '.join(first_team)+' and ' + ', '.join(second_team)+ ',\\nI predict ' + ', '.join(test_team[predicted_win]) + ' with a '+\"{:.2%}\".format(pipe.predict_proba(X_predict)[0][predicted_win])+' chance')\n",
    "#print(all_runs.sort_values(by='Probability'))\n",
    "\n",
    "\n",
    "first_team = all_runs.loc[all_runs.Probability ==all_runs.Probability.min(), 'Team 1'].values[0]\n",
    "second_team = all_runs.loc[all_runs.Probability ==all_runs.Probability.min(), 'Team 2'].values[0]\n",
    "predicted_win= all_runs.loc[all_runs.Probability ==all_runs.Probability.min(), 'Predicted Team'].values[0]-1\n",
    "\n",
    "test_team = [first_team, second_team]\n",
    "probability = all_runs.Probability.min()\n",
    "\n",
    "print('\\n\\nFor '+ ', '.join(all_names)+',\\nThe most even teams are '+ ', '.join(first_team)+' and ' + ', '.join(second_team)+ ',\\nI predict ' + ', '.join(test_team[predicted_win]) + ' with a '+\"{:.2%}\".format(probability)+' chance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbfdc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "names = []\n",
    "stats= {}\n",
    "sheets_stats = [['Name', 'Predictive Rating']]\n",
    "for name in games.Name.unique():\n",
    "    only_team=[name]\n",
    "    predicted_games = []\n",
    "    team_values = []\n",
    "    for team in range(2):\n",
    "        #print('team ', team)\n",
    "        names = []\n",
    "        for name in only_team:\n",
    "            name_stats = games_copy.loc[(games_copy.Name==name)].tail(MAX_NUMBER_OF_GAMES).iloc[:,6:].median()\n",
    "            name_stats['Win Ratio'] = games_copy.loc[(games_copy.Name==name),'Win'].tail(MAX_NUMBER_OF_GAMES).mean()\n",
    "            name_stats['Avg Rank'] = games_copy.loc[(games_copy.Name==name),'Normalized Rank'].tail(MAX_NUMBER_OF_GAMES).mean()\n",
    "            names += [name_stats]\n",
    "            names[-1].loc['Win_avg'] = games_copy.loc[(games_copy.Name==name)&\n",
    "                                                      (~games_copy.Team.isna())].Win.fillna(0).tail(MAX_NUMBER_OF_GAMES).mean()\n",
    "        team_values  += [pd.concat(names, axis = 1).T.sum()]\n",
    "    predicted_games +=[team_values[0]]\n",
    "    X_predict = pd.concat(predicted_games, axis = 1).T[prediction_columns]\n",
    "    #predicted_win = pipe.predict(X_predict)[0]\n",
    "    probability = pipe.predict_proba(X_predict)[0][1] #the player should always be 1\n",
    "    #stats[name] = -math.log((1 - probability)/probability)\n",
    "    stats[name] = probability\n",
    "    #sheets_stats +=[[name, -math.log((1 - probability)/probability)]]\n",
    "    sheets_stats +=[[name, probability]]\n",
    "    games.loc[games.Name==name, 'Predictive Rating'] = stats[name]\n",
    "\n",
    "RANGE = \"'Team Maker'!P1:Q\"+str(len(sheets_stats))\n",
    "push_sheet_data(SCOPES,SPREADSHEET_ID,RANGE, sheets_stats)    \n",
    "\n",
    "#make a quick plot to ensure easy isn't getting a good deal\n",
    "games.groupby('Name')['Predictive Rating'].max().sort_values().plot.barh()\n",
    "plt.title('Ranking based on last '+str(MAX_NUMBER_OF_GAMES)+' games')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6ee647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% update Tableau's Data spreadsheet and the google sheet's team maker info\n",
    "games.to_excel('Generals Statistics.xlsx',sheet_name=\"Games\")\n",
    "\n",
    "\n",
    "v2 = []\n",
    "v3 = []\n",
    "v4 = []\n",
    "for i in range(256):\n",
    "    if i == 0:\n",
    "        sheets_stats[0]+=['4v4']    \n",
    "    number = bin(i+1).replace('0b',\"\")\n",
    "    if (sum([int(x) for x in number])==4) & (len(number)==8):\n",
    "        v4 +=[number]\n",
    "        try:\n",
    "            sheets_stats[len(v4)]+=[number]\n",
    "        except:\n",
    "            sheets_stats+=[[\"\", \"\", number]]\n",
    "for i in range(64):\n",
    "    if i == 0:\n",
    "        sheets_stats[0]+=['3v3']    \n",
    "    number = bin(i+1).replace('0b',\"\")\n",
    "    if (sum([int(x) for x in number])==3) & (len(number)==6):\n",
    "        v3 +=[number]\n",
    "        sheets_stats[len(v3)]+=[number]\n",
    "for i in range(16):\n",
    "    if i == 0:\n",
    "        sheets_stats[0]+=['2v2']\n",
    "    number = bin(i+1).replace('0b',\"\")\n",
    "    if (sum([int(x) for x in number])==2) & (len(number)==4):\n",
    "        v2 +=[number]\n",
    "        sheets_stats[len(v2)]+=[number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54668446",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "#%%\n",
    "from openpyxl import load_workbook\n",
    "workbook = load_workbook(filename=\"Generals Statistics.xlsx\")\n",
    "workbook.create_sheet('Teams')\n",
    "sheet = workbook['Teams']\n",
    "for i, rows in enumerate(sheets_stats):\n",
    "    sheet.cell(row=i+1, column=1).value = rows[0]\n",
    "    sheet.cell(row=i+1, column=2).value = rows[1]\n",
    "    try:\n",
    "        sheet.cell(row=i+1, column=3).value = rows[2]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        sheet.cell(row=i+1, column=4).value = rows[3]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        sheet.cell(row=i+1, column=5).value = rows[4]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "sheet.cell(row=len(games.Name.unique())+1, column=1).value = 'None'\n",
    "sheet.cell(row=len(games.Name.unique())+1, column=2).value = 0\n",
    "workbook.save(filename=\"Generals Statistics.xlsx\")   \n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
